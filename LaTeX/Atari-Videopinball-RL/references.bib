% Encoding: UTF-8


@misc{mnih2013playingatarideepreinforcement,
      title={Playing Atari with Deep Reinforcement Learning}, 
      author={Volodymyr Mnih and Koray Kavukcuoglu and David Silver and Alex Graves and Ioannis Antonoglou and Daan Wierstra and Martin Riedmiller},
      year={2013},
      eprint={1312.5602},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1312.5602}, 
}

@book{sutton-2018,
	author = {Sutton, Richard S. and Barto, Andrew G.},
	month = {11},
	publisher = {MIT Press},
	title = {{Reinforcement Learning, second edition}},
	year = {2018},
}

@book{newman2018atari,
  title={Atari age: The emergence of video games in America},
  author={Newman, Michael Z},
  year={2018},
  publisher={MIT Press}
}

@article{van_Hasselt_Guez_Silver_2016,
    title={Deep Reinforcement Learning with Double Q-Learning},
    volume={30},
    url={https://ojs.aaai.org/index.php/AAAI/article/view/10295},
    DOI={10.1609/aaai.v30i1.10295},
    number={1},
    journal={Proceedings of the AAAI Conference on Artificial Intelligence},
    author={van Hasselt, Hado and Guez, Arthur and Silver, David},
    year={2016},
    month={Mar.}
}


@InProceedings{pmlr-v48-wangf16,
  title = 	 {Dueling Network Architectures for Deep Reinforcement Learning},
  author = 	 {Wang, Ziyu and Schaul, Tom and Hessel, Matteo and Hasselt, Hado and Lanctot, Marc and Freitas, Nando},
  booktitle = 	 {Proceedings of The 33rd International Conference on Machine Learning},
  pages = 	 {1995--2003},
  year = 	 {2016},
  editor = 	 {Balcan, Maria Florina and Weinberger, Kilian Q.},
  volume = 	 {48},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {New York, New York, USA},
  month = 	 {20--22 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v48/wangf16.pdf},
  url = 	 {https://proceedings.mlr.press/v48/wangf16.html},
  abstract = 	 {In recent years there have been many successes of using deep representations in reinforcement learning. Still, many of these applications use conventional architectures, such as convolutional networks, LSTMs, or auto-encoders. In this paper, we present a new neural network architecture for model-free reinforcement learning. Our dueling network represents two separate estimators: one for the state value function and one for the state-dependent action advantage function. The main benefit of this factoring is to generalize learning across actions without imposing any change to the underlying reinforcement learning algorithm. Our results show that this architecture leads to better policy evaluation in the presence of many similar-valued actions. Moreover, the dueling architecture enables our RL agent to outperform the state-of-the-art on the Atari 2600 domain.}
}

@misc{schaul2016prioritizedexperiencereplay,
      title={Prioritized Experience Replay}, 
      author={Tom Schaul and John Quan and Ioannis Antonoglou and David Silver},
      year={2016},
      eprint={1511.05952},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1511.05952}, 
}

@article{dietterich2000hierarchical,
  title={Hierarchical reinforcement learning with the MAXQ value function decomposition},
  author={Dietterich, Thomas G},
  journal={Journal of artificial intelligence research},
  volume={13},
  pages={227--303},
  year={2000}
}

@article{taylor2009transfer,
  title={Transfer learning for reinforcement learning domains: A survey.},
  author={Taylor, Matthew E and Stone, Peter},
  journal={Journal of Machine Learning Research},
  volume={10},
  number={7},
  year={2009}
}

@misc{gymnasium,
	title = {{Gymnasium documentation}},
	url = {https://gymnasium.farama.org/environments/atari/video_pinball/},
}

@inproceedings{ioffe2015batch,
  title={Batch normalization: Accelerating deep network training by reducing internal covariate shift},
  author={Ioffe, Sergey and Szegedy, Christian},
  booktitle={International conference on machine learning},
  pages={448--456},
  year={2015},
  organization={pmlr}
}

@inproceedings{nair2010rectified,
  title={Rectified linear units improve restricted boltzmann machines},
  author={Nair, Vinod and Hinton, Geoffrey E},
  booktitle={Proceedings of the 27th international conference on machine learning (ICML-10)},
  pages={807--814},
  year={2010}
}